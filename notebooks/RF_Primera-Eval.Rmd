---
title: "RF_First_Eval"
author: "G7"
date: "2024-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

```{r}
packages <- c('tidyverse', 'rpart', 'rpart.plot', 'gtools', 'Rmisc', 'scales', 'viridis', 'caret', 'AMR', 'randomForest', 'fastDummies', 'rattle', 'xgboost', 'ggpubr', 'reshape2', 'mlbench', 'readxl', 'ranger', 'tidymodels', 'parallel', 'doParallel', 'ggpubr', 'caret')

suppressWarnings({
  if (sum(as.numeric(!packages %in% installed.packages())) != 0) {
    instalador <- packages[!packages %in% installed.packages()]
    for (i in 1:length(instalador)) {
      install.packages(instalador, dependencies = TRUE)
      break
    }
  }
  sapply(packages, require, character.only = TRUE)
})

```

# Regression 
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```
## VARIABLE SELECTION FOR FIRST EVALUATION
```{r}
X1.1 = df2[,2:49]
X1.2 = df2[,61:67]
X = bind_cols(X1.1, X1.2)
X = data.frame(scale(X, center = TRUE, scale = TRUE))
X$pri_eval_num_ok = df2$pri_eval_num_ok
```


## Model with no parameter setting-FIRST EVALUATION-
```{r}
# Model creation and training
# ==============================================================================
set.seed(123)
modelo  <- ranger(
            formula   = pri_eval_num_ok ~ .,
            data      = X,
            num.trees = 10,
            seed      = 123
           )

print(modelo)
```
```{r}
predict(modelo, X) %>% head
```
## Ealuating the model
```{r}
# Training data
p_train <- predict(modelo, X)

# Evaluation data frame (Training)
eval_train <- data.frame(obs=X$pri_eval_num_ok,
                         pred=p_train)
head(eval_train)

predicciones <- p_train$predictions
```

```{r}
# Evaluation function
evaluate <- function(pred, obs) {
  mse <- mean((pred - obs)^2)
  rmse_ <- sqrt(mse)
  mae <- mean(abs(pred - obs))
  r_squared <- 1 - (sum((obs - pred)^2) / sum((obs - mean(obs))^2))

  cat("MSE:", mse, "\n")
  cat("RMSE:", rmse_, "\n")
  cat("MAE:", mae, "\n")
  cat("R-squared:", r_squared, "\n")
}

# Using the evaluation function
evaluate(predicciones, X$pri_eval_num_ok)
```

## Hyperparameter setting
### Grid-search con LOO
```{r}
# DEFINITION OF THE MODEL AND THE HYPERPARAMETERS TO BE OPTIMIZED
# ==============================================================================
modelo <- rand_forest(
             mode  = "regression",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

# DEFINITION OF PREPROCESSING 
# ==============================================================================
# In this case there is no preprocessing, so the transformer contains only the formula definition and the training data.
# the formula definition and the training data.
transformer <- recipe(
                  formula = pri_eval_num_ok ~ .,
                  data    =  X
               )

# DEFINITION OF THE VALIDATION STRATEGY AND CREATION OF PARTITIONS
# ==============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = X,
              v       = nrow(X),
              repeats = 1,
              strata  = pri_eval_num_ok
            )

# WORKFLOW
# ==============================================================================
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

# GRID OF HIPERPARAMETERS
# ==============================================================================
hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

# EXECUTION OF HYPERPARAMETER OPTIMIZATION #==============================================================================
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(rmse),
              grid      = hiperpar_grid
            )

stopCluster(cl)
```

```{r}
# Best hyperparameters by cross-validation #==============================================================================
show_best(grid_fit, metric = "rmse", n = 1)
```

### Training the model with the best hyperparameters
```{r}
# FINAL TRAINING
# =============================================================================
mejores_hiperpar <- select_best(grid_fit, metric = "rmse")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X
                    ) %>%
                    extract_fit_parsnip()
```

```{r}
# Final model training error
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(
                  new_data = X,
                  type     = "numeric"
                )

predicciones <- predicciones %>% 
                bind_cols(X %>% dplyr::select(pri_eval_num_ok))

rmse_test  <- rmse(
                 data     = predicciones,
                 truth    = pri_eval_num_ok,
                 estimate = .pred,
                 na_rm    = TRUE
              )
rmse_test
```
## Importance of predictors

Importance by node purity

In the above models, the importance argument defaults to “none”. This disables the calculation of predictor importance to reduce training time. The model is trained again, with the best hyperparameters found, but this time with importance = “impurity”. The ranger models calculate impurity from the Gini index in classification problems and with the variance in regression.
```{r}
# model training
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(pri_eval_num_ok ~., data = X)

# Importance
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Graph
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importance of predictors (node purity)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none",axis.text = element_text(size = 5))
```
## TOP 15
```{r}
# Filtering to keep only the 15 most important variables
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

# Chart of the 15 most important variables
ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importance of predictors (node purity)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))
```

## Importance by permutation
The model is trained again, with the best hyperparameters found, but this time indicating importance = “permutation”.
```{r}
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(pri_eval_num_ok ~., data = X)

importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importance of predictors (permutation)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none",axis.text = element_text(size = 5))
```
## TOP 15
```{r}
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          slice_max(order_by = importancia, n = 15)  

ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importance of predictors (permutation)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))
```

Both strategies identify Tox_grade, Toxicity, Lymph_1eval, PLR_1C and NLR_1eval as the most influential predictors, according to the training data.

# Classification
```{r}
# Remove all objects from the global environment and the console
rm(list = ls())
cat("\014")
```
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```
## VARIABLE SELECTION FOR FIRST EVALUATION
```{r SELECCION DE VARIABLES PARA PRIMERA EVAL}
X1.1 = df2[,2:49]
X1.2 = df2[,61:67]
X2 = bind_cols(X1.1, X1.2)
X2 = data.frame(scale(X2, center = TRUE, scale = TRUE))
X2$pri_eval_num_ok <- as.factor(df2$pri_eval_num_ok)
```

## Model without hyperparameters
```{r}
set.seed(123)
modelo_sin_ajustar  <- ranger(
            formula   = pri_eval_num_ok ~ .,
            data      = X2,
            num.trees = 10,
            seed      = 123
           )

print(modelo_sin_ajustar)
```

```{r}
predict(modelo_sin_ajustar, X2) %>% head
```
## Ealuating the model
```{r}
# Training data
p_train <- predict(modelo_sin_ajustar, X2)

# Evaluation data frame (Training)
eval_train <- data.frame(obs=X2$pri_eval_num_ok,
                         pred=p_train)
head(eval_train)

predicciones_ <- p_train$predictions

```

```{r}
predictions <- predict(modelo_sin_ajustar, X2, type = "response")

predicciones_ <- predictions$predictions

eval_train <- data.frame(
  obs = X2$pri_eval_num_ok,  
  pred = as.factor(predicciones_)  
)

conf_matrix <- confusionMatrix(eval_train$pred, eval_train$obs)
print(conf_matrix)
```

## Improvement of hyperparameters
```{r}
modelo <- rand_forest(
             mode  = "classification",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

transformer <- recipe(
                  formula = pri_eval_num_ok ~ .,
                  data    =  X2
               )

set.seed(1234)
cv_folds <- vfold_cv(
              data    = X2,
              v       = nrow(X2),
              repeats = 1,
              strata  = pri_eval_num_ok
            )

workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X2)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(f_meas),
              grid      = hiperpar_grid
            )

stopCluster(cl)
```

```{r}
show_best(grid_fit, metric = "f_meas", n = 1)
```

```{r}
mejores_hiperpar <- select_best(grid_fit, metric = "f_meas")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X2
                    ) %>%
                   extract_fit_parsnip
```

```{r}
predicciones <- modelo_final_fit %>%
                predict(new_data = X2)

predicciones <- predicciones %>% 
                bind_cols(X2 %>% dplyr::select(pri_eval_num_ok))

accuracy_test  <- accuracy(
                     data     = predicciones,
                     truth    = pri_eval_num_ok,
                     estimate = .pred_class,
                     na_rm    = TRUE
                  )
accuracy_test
```

```{r}
mat_confusion <- predicciones %>%
                 conf_mat(
                   truth     = pri_eval_num_ok,
                   estimate  = .pred_class
                 )
mat_confusion
```

## Probability prediction
Most Random Forest implementations, including ranger, allow predicting probabilities when dealing with classification problems. It is important to understand how these values are calculated in order to interpret and use them correctly.

In the example above, applying predict() returns Yes (high sales) or No (low sales) for each test observation. However, no information is available on how reliably the model performs this assignment. With predict(type=“prob”), instead of a classification, we obtain the probability with which the model considers that each observation may belong to each of the classes.
```{r}
predicciones <- modelo_final_fit %>%
                predict(new_data = X2, type = "prob")
head(predicciones, 4)
```

The result of predict(type=“prob”) is a dataframe with one row per observation and as many columns as the number of classes of the response variable. The value of the first column corresponds to the probability, according to the model, that the observation belongs to class No, and so on. The probability value shown for each prediction corresponds to the fraction of observations of each class at the terminal nodes reached by the predicted observation in the set of trees.

By default, predict() assigns each new observation to the class with the highest probability (in case of a tie it is assigned randomly). However, this need not be the desired behavior in all cases.

## Importance of predictors

Importance by node purity

In the above models, the importance argument defaults to “none”. This disables the calculation of predictor importance to reduce training time. The model is trained again, with the best hyperparameters found, but this time with importance = “impurity”. The ranger models calculate impurity from the Gini index in classification problems and with the variance in regression.

```{r}
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(pri_eval_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importance of predictors (node purity)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```

## TOP 15
```{r}
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importance of predictors (node purity)") +
geom_col() +
scale_fill_viridis_c() +  
coord_flip() +  
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))
```


## Importance by permutation
The model is trained again, with the best hyperparameters found, but this time indicating importance = “permutation”.
```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(pri_eval_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importance of predictors (permutatión)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```

## Top 15
```{r}
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importance of predictors (permutation)") +
geom_col() +
scale_fill_viridis_c() +  
coord_flip() +
theme_bw() +  
theme(legend.position = "none", axis.text = element_text(size = 12))  
```

Both strategies identify SII_2C, PLR_1C, SII_1C, NLR_1C, PLR_pre, N_cycles and Lymph_tot as the most influential predictors, according to the training data.







